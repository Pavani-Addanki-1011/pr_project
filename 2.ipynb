{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0cd87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Event ID  Magnitude  Depth (km) Time of Occurrence   Latitude   Longitude  \\\n",
      "0         1        6.1          21         06-04-2023  33.996715 -118.345031   \n",
      "1         2        7.9          15         02-08-2023  34.051518 -117.751207   \n",
      "2         3        7.2          11         21-10-2023  33.796659 -118.695034   \n",
      "3         4        6.8          28         28-07-2023  34.020960 -118.171458   \n",
      "4         5        5.5          18         09-12-2023  34.211914 -118.667428   \n",
      "\n",
      "   PGA (Peak Ground Acceleration)  EEWS Warning Time (s)  \\\n",
      "0                            0.32                     35   \n",
      "1                            0.33                     29   \n",
      "2                            0.38                     48   \n",
      "3                            0.30                     25   \n",
      "4                            0.43                     48   \n",
      "\n",
      "   EEWS False Alarm Rate Cascading Event Cascading Event Type  \\\n",
      "0                   0.08             Yes            Landslide   \n",
      "1                   0.04              No                    -   \n",
      "2                   0.03              No     Building Failure   \n",
      "3                   0.05              No                    -   \n",
      "4                   0.08             Yes                    -   \n",
      "\n",
      "   Building Failure Rate  Landslide Probability  \\\n",
      "0                    NaN                   0.62   \n",
      "1                   0.14                    NaN   \n",
      "2                   0.15                   0.12   \n",
      "3                   0.49                    NaN   \n",
      "4                    NaN                   0.31   \n",
      "\n",
      "   Infrastructure Damage Cost (in USD)  Fatalities  \n",
      "0                               143322           4  \n",
      "1                                    0           4  \n",
      "2                               261661           4  \n",
      "3                               355919           1  \n",
      "4                                    0           8  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "could not convert string to float: '06-04-2023'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:786\u001b[0m, in \u001b[0;36mnanmedian\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 786\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;66;03m# e.g. \"could not convert string to float: 'a'\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '06-04-2023'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCascading Event Type\u001b[39m\u001b[38;5;124m'\u001b[39m], prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCascadingEvent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 7. Check for any remaining NaNs and handle them\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfillna(df\u001b[38;5;241m.\u001b[39mmedian())  \u001b[38;5;66;03m# Replace remaining NaNs with the median\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# 8. Data type conversion (if needed for specific columns)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFatalities\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFatalities\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11623\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.median\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11606\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11607\u001b[0m     _num_doc,\n\u001b[0;32m  11608\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the median of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11621\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11622\u001b[0m ):\n\u001b[1;32m> 11623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmedian(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11212\u001b[0m, in \u001b[0;36mNDFrame.median\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmedian\u001b[39m(\n\u001b[0;32m  11206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11207\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11210\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11211\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmedian, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11214\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[38;5;241m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11159\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11160\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10519\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  10515\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  10517\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  10518\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 10519\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[0;32m  10520\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor(res)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  10521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1534\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1532\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1534\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[0;32m   1535\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1537\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:339\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 339\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;66;03m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m    343\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[result]])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10482\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  10480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_reduce(name, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m  10481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 10482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:789\u001b[0m, in \u001b[0;36mnanmedian\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    786\u001b[0m         values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# e.g. \"could not convert string to float: 'a'\"\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(err)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    791\u001b[0m     values[mask] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "\u001b[1;31mTypeError\u001b[0m: could not convert string to float: '06-04-2023'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the data (assuming it's in a CSV format, adjust accordingly)\n",
    "df = pd.read_csv('Comprehensive_Earthquake_Dataset.csv')\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())\n",
    "\n",
    "# 1. Save the original 'Time of Occurrence' column before converting to datetime\n",
    "df['Original Time of Occurrence'] = df['Time of Occurrence']\n",
    "\n",
    "# 2. Convert the 'Time of Occurrence' column to datetime for analysis\n",
    "df['Time of Occurrence'] = pd.to_datetime(df['Time of Occurrence'], format='%d-%m-%Y', errors='coerce')\n",
    "\n",
    "# 3. Handling missing values:\n",
    "# Replace missing numeric values with the median of the column\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())\n",
    "\n",
    "# Replace missing categorical values with a placeholder, e.g., 'Unknown'\n",
    "categorical_columns = df.select_dtypes(include=[object]).columns\n",
    "df[categorical_columns] = df[categorical_columns].fillna('Unknown')\n",
    "\n",
    "# 4. Convert the Latitude and Longitude columns to numeric, handling any errors\n",
    "df['Latitude'] = pd.to_numeric(df['Latitude'], errors='coerce')\n",
    "df['Longitude'] = pd.to_numeric(df['Longitude'], errors='coerce')\n",
    "\n",
    "# 5. Convert 'Cascading Event' to a binary numeric value\n",
    "df['Cascading Event'] = df['Cascading Event'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# 6. If 'Cascading Event Type' is a key feature, one-hot encode it\n",
    "df = pd.get_dummies(df, columns=['Cascading Event Type'], prefix='CascadingEvent')\n",
    "\n",
    "# 7. Check for any remaining NaNs and handle them\n",
    "df = df.fillna(df.median())  # Replace remaining NaNs with the median\n",
    "\n",
    "# 8. Data type conversion (if needed for specific columns)\n",
    "df['Fatalities'] = df['Fatalities'].astype(int)\n",
    "df['Building Failure Rate'] = pd.to_numeric(df['Building Failure Rate'], errors='coerce')\n",
    "\n",
    "# 9. Ensure all numeric columns are properly formatted\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Final Check: Preview the processed data\n",
    "print(df.info())  # Check data types and null values\n",
    "print(df.head())  # View the first few rows of the processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c7ae72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as 'cleaned123456.csv'\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "\n",
    "df.to_csv(\"cleaned123456.csv\", index=False)\n",
    "print(\"Dataset saved as 'cleaned123456.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb0ab81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
